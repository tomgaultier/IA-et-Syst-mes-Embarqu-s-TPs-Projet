{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction à la quantization \n",
        "\n",
        "Laurent cetinsoy\n",
        "\n",
        "Les réseaux de neurones prennent beaucoup de place et il peut être difficile de les faire rentrer sur certains dispositifs embarqués. \n",
        "\n",
        "Il existe plusieurs méthodes pour réduire la taille et augmenter la vitesse d'executer des réseaux de neurone. Par exemple il y a ce qu'on appelle la quantization et le pruning.\n",
        "\n",
        "Dans ce notebook on va faire une introduction à la quantization avec la librairie tensorflow lite.\n",
        "\n",
        "\n",
        "## Quantization post training\n",
        "\n",
        "Dans un premier temps on va quantifier notre réseau après l'avoir entraîné normalement. \n",
        "\n",
        "\n",
        "Entraîner un réseau de neurone convolutionnel simple avec keras pour faire de la classification MNIST (ou un autre dataset simple de votre choix si (vous en avez marre de ce dataset - https://keras.io/api/datasets/)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "efc9100a06c04d0b8b17c557d7cbbd41",
        "deepnote_cell_type": "markdown",
        "id": "EaiUu_PbLAjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1) / 255\n",
        "x_train.shape\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255\n",
        "x_train.shape\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "87bc3d9f649e416983c0ee9b59bd2de6",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_buJDoJaLAjR",
        "outputId": "2570b372-8a7d-43a2-9900-39ef4133fe3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "1875/1875 [==============================] - 217s 114ms/step - loss: 0.1050 - accuracy: 0.9686 - val_loss: 0.0463 - val_accuracy: 0.9840\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd48a402190>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afficher le nombre de paramètre du modèle"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "b984ac621a2249d1b955535f9f9ab55b",
        "deepnote_cell_type": "markdown",
        "id": "GMlOroVTLAjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "11935acab177492cbcd4a8aafea0bdf0",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVOxirK4LAjT",
        "outputId": "0afbec15-595e-4cad-ef94-e214bccd0762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               1843400   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,864,226\n",
            "Trainable params: 1,864,226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sauvegarder votre modèle et afficher la taille du fichier. Si on applique une bête règle de trois, quelle est la taille occupée par paramètre ? "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "4782a0f186d14d4e91cfd903998f8710",
        "deepnote_cell_type": "markdown",
        "id": "amPAKiZGLAjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Taille du fichier: \",os.path.getsize(\"model.h5\"), \"octets\" )\n",
        "\n",
        "print(\"Taille occupée par parametre: \", os.path.getsize(\"model.h5\")/model.count_params() , \"octets\" )"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "8f50426e286c4cf39610c41ed5cdfeb7",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6FTb1PALAjU",
        "outputId": "5b8730cd-7209-42e9-94ca-b3fc5d5bc1fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du fichier:  22414000 octets\n",
            "Taille occupée par parametre:  12.023220360621513 octets\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va maintenant convertir notre modèle keras en modèle tensorflow lite. \n",
        "\n",
        "Installer la librairie tensorflow lite créer une instance de la class TFLiteConverter à partir de votre modèle keras\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "2e0f0d5c02dc40db9fae96aa67d4de06",
        "deepnote_cell_type": "markdown",
        "id": "yN3HQ5piLAjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"model.h5\")\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "8c1f6d62ff6a416aa3ec3b05ebccddb9",
        "deepnote_cell_type": "code",
        "id": "ZQpe8RYJLAjU"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertir votre modèle et le sauvegarder dans un fichier nommé model.tflite. Sa taille est-elle plus petite ? "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "13a2cc6cc09f4e799d4e8641521ece8e",
        "deepnote_cell_type": "markdown",
        "id": "ZjHV1i28LAjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Taille du fichier Keras: \",os.path.getsize(\"model.h5\"), \"octets\" )\n",
        "print(\"Taille du fichier Tensorflow Lite: \",os.path.getsize(\"model.tflite\"), \"octets\" )"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "2ca07a9b6ee74a6594c3a33313decfc0",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75GhA8gLLAjV",
        "outputId": "3f675505-2222-49d3-de5f-7851f0244fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du fichier Keras:  22414000 octets\n",
            "Taille du fichier Tensorflow Lite:  7460112 octets\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va maintenant spécifier des optimisations au converter. \n",
        "\n",
        "1. Recréer un converter\n",
        "\n",
        "2. modifier son attribut optimizations pour ajouter une liste d'optimisation avec la valeur tf.lite.Optimize.DEFAULT\n",
        "\n",
        "3. Relancer la conversion du modèle, sauvegarder le modèle et regarder la taille du fichier généré"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "0e707074068f44ffad07b9301948782b",
        "deepnote_cell_type": "markdown",
        "id": "gWVGSzBsLAjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"model.h5\")\n",
        "\n",
        "converter_optimized = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "converter_optimized.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model_optimized = converter_optimized.convert()\n",
        "\n",
        "with open('model_optimized.tflite', 'wb') as f:\n",
        "    f.write(tflite_model_optimized)\n",
        "  \n",
        "import os\n",
        "print(\"Taille du modèle optimisé:\", os.path.getsize('model_optimized.tflite'), \"octets\")"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "42b10a79262949aeadb6f2f82eae6f58",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izFKkXi5LAjW",
        "outputId": "cf3c2b2f-c556-424f-9ec9-a3656f5d4d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du modèle optimisé: 1870128 octets\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quelle type  de quantization Optimize.Default, utilise-t-elle ?\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "e083971b3c7647818e1532ed9c7edb41",
        "deepnote_cell_type": "markdown",
        "id": "52TXaAstLAjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "c4952d60d77243439193b6e9b4d573e9",
        "deepnote_cell_type": "markdown",
        "id": "vq5kCEFBLAjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization aware training \n",
        "\n",
        "Dans cette section on va s'intéresser à l'entraînement sensible à la quantification. L'idée est de simuler les effets de la quantification pendant l'entraînement pour que le modèle ajuste les poids afin de tenir ocmpte de la quantification. \n",
        "\n",
        "Reprendre le modèle entraîné sur MNIST\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "0bfeb7a588454ae6942059d7d79be609",
        "deepnote_cell_type": "markdown",
        "id": "Brv6BgnILAjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1) / 255\n",
        "x_train.shape\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255\n",
        "x_train.shape\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "11d35b87030b49eb99c77c4a6fe47db3",
        "deepnote_cell_type": "code",
        "id": "1rMve9WZLAjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f2e008-3a51-4b9f-be0c-58bc9adace22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 197s 104ms/step - loss: 0.1097 - accuracy: 0.9659 - val_loss: 0.0374 - val_accuracy: 0.9873\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5091402e0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "A l'aide de la fonction quantize de tensorflow_model_optimization, créer une seconde version de votre modèle entraîné nommé qat_model"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "af90aac8bbb94f86b728031f5ae0a66f",
        "deepnote_cell_type": "markdown",
        "id": "mHJ6TheCLAjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch-yHJUruzhi",
        "outputId": "fc20f0ca-17a5-450d-c3d2-f921b35c1420"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (1.22.4)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "qat_model = tfmot.quantization.keras.quantize_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gS0SAENreTt",
        "outputId": "06d50bd1-02c1-4bf7-eabf-ffe4a11f05f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiler le modèle"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "868beffe9e8740d98cbfd8458af4117a",
        "deepnote_cell_type": "markdown",
        "id": "1U44IZKwLAjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qat_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3mD1vDbQu7s6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afficher le summury du modèle. D'après vous ce modèle est-il quantifié ? "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "4dddea973f404fb699b134a67d1a2dc5",
        "deepnote_cell_type": "markdown",
        "id": "msl2osFWLAjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qat_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL8OdT7AvH_S",
        "outputId": "85d54ae1-429a-4f39-edc4-89ee78ff65db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 28, 28, 1)        3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_conv2d (QuantizeWrapp  (None, 26, 26, 32)       387       \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantizeWra  (None, 24, 24, 64)       18627     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_max_pooling2d (Quanti  (None, 12, 12, 64)       1         \n",
            " zeWrapperV2)                                                    \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWrap  (None, 9216)             1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrappe  (None, 200)              1843405   \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_dense_1 (QuantizeWrap  (None, 10)               2015      \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,864,439\n",
            "Trainable params: 1,864,226\n",
            "Non-trainable params: 213\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Réentraîner votre modèle sur un sous ensemble des modèles sur une ou deux epochs et afficher la performance sur le train et test set"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "7b3a873512174205b6d6f4aacd7480c8",
        "deepnote_cell_type": "markdown",
        "id": "z1Fr4U0QLAjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qat_model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test))\n",
        "\n",
        "qat_model.evaluate(x_test, y_test)\n",
        "\n",
        "qat_model.evaluate(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Qnb3GZvnC6",
        "outputId": "86667199-72f4-40b2-ebd9-db6b0f4f3905"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 243s 129ms/step - loss: 0.4104 - accuracy: 0.8805 - val_loss: 0.1010 - val_accuracy: 0.9678\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 270s 144ms/step - loss: 0.0824 - accuracy: 0.9754 - val_loss: 0.0569 - val_accuracy: 0.9808\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd487049a90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertir votre modèle avec TFLite"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "cc4f49a0e7894b8385e90c2330a55bb1",
        "deepnote_cell_type": "markdown",
        "id": "pgpBWibyLAjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
        "\n",
        "converter_optimized.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_qat_model_optimized = converter_optimized.convert()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "68918464bfb14b749d3848fe25b5e02e",
        "deepnote_cell_type": "code",
        "id": "ddbXpXqmLAja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d680f6-34d4-4a93-f417-5e02641a9a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparer la performance du modèle Quantified aware training, au modèle original et au modèle quantifié post training"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d80e6fbfea9646919a9cbe2c8fa41b2d",
        "deepnote_cell_type": "markdown",
        "id": "ikJtF5mtLAja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation du modèle Quantified aware training\n",
        "quantized_aware_train_loss, quantized_aware_train_accuracy = qat_model.evaluate(x_test, y_test)\n",
        "\n",
        "# Evaluation du modèle original\n",
        "original_loss, original_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Evaluation du modèle quantifié post-training\n",
        "quantized_post_train_loss, quantized_post_train_accuracy = tflite_qat_model_optimized.evaluate(x_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Performance du modèle original : loss = {:.4f}, accuracy = {:.4f}\".format(original_loss, original_accuracy))\n",
        "print(\"Performance du modèle quantifié post-training : loss = {:.4f}, accuracy = {:.4f}\".format(quantized_post_train_loss, quantized_post_train_accuracy))\n",
        "print(\"Performance du modèle Quantified aware training : loss = {:.4f}, accuracy = {:.4f}\".format(quantized_aware_train_loss, quantized_aware_train_accuracy))"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "bdd43405f5fd46ce892d957bb43a353a",
        "deepnote_cell_type": "code",
        "id": "XEh0uTM8LAja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "9cba8f4c-8bbf-41c7-851b-9268fa3cbf9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 9s 29ms/step - loss: 0.0918 - accuracy: 0.9685\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.0374 - accuracy: 0.9873\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-9c3785bebf6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Evaluation du modèle quantifié post-training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mquantized_post_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantized_post_train_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflite_qat_model_optimized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'evaluate'"
          ]
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sauvegarder le modèle QAT et comparer les tailles des modèles"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "6472c7a129394639838f76381e562588",
        "deepnote_cell_type": "markdown",
        "id": "YDVRycyrLAja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qat_model.save(\"qat_model.h5\")\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Taille du modèle original : \", os.path.getsize('model.h5'))\n",
        "print(\"Taille du modèle quantifié post-entraînement : \", os.path.getsize('quantized_model.tflite'))\n",
        "print(\"Taille du modèle QAT : \", os.path.getsize('qat_model.h5'))\n",
        "\n",
        "print(\"Taille du modèle original: \",os.path.getsize(\"model.h5\"), \"octets\" )\n",
        "print(\"Taille du modèle QAT: \",os.path.getsize(\"qat_model.h5\"), \"octets\" )\n",
        "print(\"Taille du modèle original: \",os.path.getsize(\"model.h5\"), \"octets\" )"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d3c2951a1fd14be3b5e3c85e05a056ea",
        "deepnote_cell_type": "code",
        "id": "9k_XJ6YRLAja"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus : déployer votre modèle sur votre téléphone ou un dispositif embarqué si vous en disposez d'un. "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "4a006a6d1a194e418072192da1a920de",
        "deepnote_cell_type": "markdown",
        "id": "qWExy_CgLAjb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "927af747794641fa936ad727c6bf75d0",
        "deepnote_cell_type": "code",
        "id": "JTNnIx_sLAjb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus : Obtenir un modèle qui sera à la fois quantifié et élagué (prunned) en s'aidant de la documentation (https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "e7635cb278ab43589a851e2c2de0d8ef",
        "deepnote_cell_type": "markdown",
        "id": "rXTwb4OYLAjb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "tags": [],
        "cell_id": "a1eacb94d0aa4dbd872c8babacf8bb8d",
        "deepnote_cell_type": "code",
        "id": "a0AKJmvLLAjb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "A l'aide de tensorflow lite / tensorflow lite micro "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "71e07172d7514f8f84e744177e1bfb2b",
        "is_collapsed": false,
        "formattedRanges": [],
        "deepnote_cell_type": "text-cell-p",
        "id": "8QQSEYgzLAjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=0d51e245-899d-41d6-b23b-cf3e4bbbc6ea' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ],
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "9UAYM_B-LAjc"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote": {
      "is_reactive": false
    },
    "orig_nbformat": 2,
    "deepnote_notebook_id": "fb1d23f975ba410e92fed9f5b8cbb7e6",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  }
}